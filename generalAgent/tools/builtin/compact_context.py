"""
compact_context å·¥å…·

æä¾› Agent è°ƒç”¨æ¥å£æ¥å‹ç¼©å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œé‡Šæ”¾ token ç©ºé—´ã€‚
"""

from typing import Annotated, Literal, Optional
from langchain_core.tools import tool, InjectedToolCallId
from langchain_core.messages import RemoveMessage, ToolMessage
from langgraph.prebuilt import InjectedState
from langgraph.types import Command
from langgraph.graph.message import REMOVE_ALL_MESSAGES

from generalAgent.graph.state import AppState
from generalAgent.config.settings import get_settings
from generalAgent.context.manager import ContextManager
import logging

logger = logging.getLogger(__name__)


async def _invoke_model_for_compression(prompt: str, max_tokens: int = 1440) -> str:
    """
    ä¸ºå‹ç¼©è°ƒç”¨ LLM çš„è¾…åŠ©å‡½æ•°

    Args:
        prompt: å‹ç¼© promptï¼ˆåŒ…å«å†å²æ¶ˆæ¯ï¼‰
        max_tokens: æœ€å¤§è¾“å‡º token æ•°

    Returns:
        LLM è¿”å›çš„æ‘˜è¦æ–‡æœ¬
    """
    from langchain_openai import ChatOpenAI

    settings = get_settings()

    # ä½¿ç”¨åŸºç¡€æ¨¡å‹é…ç½®åˆ›å»ºä¸´æ—¶ LLM å®ä¾‹
    model = ChatOpenAI(
        model=settings.models.base,
        api_key=settings.models.base_api_key,
        base_url=settings.models.base_base_url,
        max_tokens=max_tokens,
        temperature=0.3
    )

    # è°ƒç”¨ LLM
    response = await model.ainvoke(prompt)

    return response.content


@tool
async def compact_context(
    state: Annotated[AppState, InjectedState],
    tool_call_id: Annotated[str, InjectedToolCallId],
    strategy: Literal["auto", "compact", "summarize"] = "auto"
) -> Command:
    """å‹ç¼©ä¼šè¯ä¸Šä¸‹æ–‡ä»¥é‡Šæ”¾ token ç©ºé—´

    å½“å¯¹è¯å†å²è¿‡é•¿æ—¶ï¼Œä½¿ç”¨æ­¤å·¥å…·å‹ç¼©ä¸Šä¸‹æ–‡ã€‚æ”¯æŒä¸¤ç§ç­–ç•¥ï¼š
    - compact: è¯¦ç»†æ‘˜è¦ï¼Œä¿ç•™æŠ€æœ¯ç»†èŠ‚ã€æ–‡ä»¶è·¯å¾„ã€å·¥å…·è°ƒç”¨ç­‰
    - summarize: æç®€æ‘˜è¦ï¼Œ200å­—ä»¥å†…ï¼Œä»…ä¿ç•™æ ¸å¿ƒä¿¡æ¯
    - auto: è‡ªåŠ¨é€‰æ‹©ç­–ç•¥ï¼ˆé»˜è®¤ï¼ŒåŸºäºå†å²å‹ç¼©æ•ˆæœå’Œæ¬¡æ•°ï¼‰

    **å‹ç¼©æ•ˆæœï¼š**
    - å‹ç¼©åçš„æ‘˜è¦ä¼šä¿ç•™å…³é”®ä¿¡æ¯ï¼Œä¸å½±å“åç»­å¯¹è¯

    **æ³¨æ„äº‹é¡¹ï¼š**
    - å‹ç¼©æ˜¯ä¸å¯é€†çš„ï¼Œæ—§æ¶ˆæ¯ä¼šè¢«æ‘˜è¦æ›¿ä»£
    - å»ºè®®åœ¨å®Œæˆé˜¶æ®µæ€§ä»»åŠ¡åå‹ç¼©ï¼Œé¿å…ä¸¢å¤±è¿›è¡Œä¸­çš„ç»†èŠ‚
    - å¦‚æœå‹ç¼©å¤±è´¥ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨é™çº§åˆ°ç®€å•æˆªæ–­ï¼ˆä¿ç•™æœ€è¿‘ 150 æ¡æ¶ˆæ¯ï¼‰

    Args:
        strategy: å‹ç¼©ç­–ç•¥ (auto/compact/summarize)

    Returns:
        å‹ç¼©ç»“æœæŠ¥å‘Š
    """
    settings = get_settings()

    # æ£€æŸ¥æ˜¯å¦å¯ç”¨ä¸Šä¸‹æ–‡ç®¡ç†
    if not settings.context.enabled:
        return Command(
            update={
                "messages": [ToolMessage(
                    content="âš ï¸ ä¸Šä¸‹æ–‡ç®¡ç†åŠŸèƒ½æœªå¯ç”¨ã€‚è¯·åœ¨é…ç½®ä¸­å¯ç”¨ CONTEXT_MANAGEMENT_ENABLED=true",
                    tool_call_id=tool_call_id
                )]
            }
        )

    # è·å–å½“å‰æ¶ˆæ¯å†å²
    messages = state.get("messages", [])
    compact_count = state.get("compact_count", 0)
    last_compression_ratio = state.get("last_compression_ratio")

    logger.info(
        f"compact_context called: strategy={strategy}, "
        f"current_messages={len(messages)}, compact_count={compact_count}"
    )

    # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ¶ˆæ¯éœ€è¦å‹ç¼©
    if len(messages) < 15:
        return Command(
            update={
                "messages": [ToolMessage(
                    content="ğŸ’¡ å½“å‰æ¶ˆæ¯æ•°é‡è¾ƒå°‘ï¼ˆ< 15 æ¡ï¼‰ï¼Œæš‚ä¸éœ€è¦å‹ç¼©ã€‚",
                    tool_call_id=tool_call_id
                )]
            }
        )

    # æ‰§è¡Œå‹ç¼©
    try:
        context_manager = ContextManager(settings)

        # Get context window from token tracker
        from generalAgent.context.token_tracker import TokenTracker
        tracker = TokenTracker(settings)
        context_window = tracker.get_context_window(settings.models.base)

        result = await context_manager.compress_context(
            messages=messages,
            model_invoker=_invoke_model_for_compression,
            context_window=context_window
        )

        # ç”Ÿæˆç”¨æˆ·å¯è§æŠ¥å‘Š
        report = context_manager.format_compression_report(result)

        logger.info(
            f"Compression successful: {result.before_count} â†’ {result.after_count} messages, "
            f"ratio={result.compression_ratio:.1%}, strategy={result.strategy}"
        )

        # âœ… Use official LangGraph API: RemoveMessage(id=REMOVE_ALL_MESSAGES)
        # æ›´æ–° state
        return Command(
            update={
                "messages": [RemoveMessage(id=REMOVE_ALL_MESSAGES)] + result.messages,  # Clear all, then add compressed
                "compact_count": compact_count + 1,
                "last_compact_strategy": result.strategy,
                "last_compression_ratio": result.compression_ratio,
                "cumulative_prompt_tokens": 0,  # é‡ç½®ç´¯ç§¯ token è®¡æ•°
                "cumulative_completion_tokens": 0,
            },
            # è¿½åŠ å·¥å…·è¿”å›æ¶ˆæ¯ï¼ˆå‘ŠçŸ¥ç”¨æˆ·å‹ç¼©ç»“æœï¼‰
            graph=Command.PARENT
        )

    except Exception as e:
        logger.error(f"Compression failed: {e}", exc_info=True)

        return Command(
            update={
                "messages": [ToolMessage(
                    content=f"âŒ ä¸Šä¸‹æ–‡å‹ç¼©å¤±è´¥: {str(e)}\n\nç³»ç»Ÿå·²å°è¯•é™çº§ç­–ç•¥ï¼Œä½†ä»ç„¶å¤±è´¥ã€‚è¯·è”ç³»ç®¡ç†å‘˜æ£€æŸ¥æ—¥å¿—ã€‚",
                    tool_call_id=tool_call_id
                )]
            }
        )


__all__ = ["compact_context"]
