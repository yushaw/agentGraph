"""
æ‰‹åŠ¨æµ‹è¯•è‡ªåŠ¨å‹ç¼©åŠŸèƒ½

æµ‹è¯•æ­¥éª¤ï¼š
1. åˆ›å»ºä¸€ä¸ªåŒ…å«å¤§é‡æ¶ˆæ¯çš„ state (æ¨¡æ‹Ÿ token è¾¾åˆ° 96%)
2. è°ƒç”¨ agent è§¦å‘è‡ªåŠ¨å‹ç¼©
3. éªŒè¯å‹ç¼©æ˜¯å¦è‡ªåŠ¨æ‰§è¡Œ
4. éªŒè¯ state æ˜¯å¦æ­£ç¡®æ›´æ–°

è¿è¡Œæ–¹å¼ï¼š
    python tests/manual/test_auto_compact.py
"""

import asyncio
import sys
import logging
from pathlib import Path

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(name)s - %(message)s')

# Add project root to path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from generalAgent.runtime.app import build_application
from generalAgent.config.settings import get_settings


async def test_auto_compression():
    """æµ‹è¯•è‡ªåŠ¨å‹ç¼©åŠŸèƒ½"""
    print("=" * 80)
    print("æµ‹è¯•è‡ªåŠ¨å‹ç¼©åŠŸèƒ½")
    print("=" * 80)

    # 1. æ„å»ºåº”ç”¨
    print("\n[1/5] æ„å»ºåº”ç”¨...")
    app, initial_state_factory, skill_registry, tool_registry, skill_config = await build_application()

    # 2. åˆ›å»ºåˆå§‹ state
    print("[2/5] åˆ›å»ºåˆå§‹ state...")
    state = initial_state_factory()

    # æ·»åŠ å¤§é‡æ¶ˆæ¯ä»¥æ¨¡æ‹Ÿé«˜ token ä½¿ç”¨
    messages = [SystemMessage(content="You are a helpful assistant.")]
    for i in range(150):
        messages.append(HumanMessage(content=f"User question {i}: " + "x" * 200))  # æ¯æ¡æ¶ˆæ¯çº¦ 200 tokens
        messages.append(AIMessage(content=f"AI response {i}: " + "y" * 200))

    state["messages"] = messages
    state["cumulative_prompt_tokens"] = 123000  # 96% of 128k (critical threshold)
    state["cumulative_completion_tokens"] = 5000
    state["compact_count"] = 0
    state["auto_compressed_this_request"] = False

    print(f"   - åˆå§‹æ¶ˆæ¯æ•°: {len(state['messages'])}")
    print(f"   - ç´¯ç§¯ prompt tokens: {state['cumulative_prompt_tokens']:,}")
    print(f"   - Token ä½¿ç”¨ç‡: {state['cumulative_prompt_tokens'] / 128000:.1%}")

    # 3. æ·»åŠ ä¸€æ¡æ–°çš„ç”¨æˆ·æ¶ˆæ¯
    print("[3/5] æ·»åŠ ç”¨æˆ·æ¶ˆæ¯è§¦å‘ planner...")
    state["messages"].append(HumanMessage(content="è¯·æ€»ç»“ä¸€ä¸‹æˆ‘ä»¬çš„å¯¹è¯"))

    # 4. æ‰§è¡Œä¸€æ¬¡ agent å¾ªç¯ï¼ˆåº”è¯¥è§¦å‘è‡ªåŠ¨å‹ç¼©ï¼‰
    print("[4/5] æ‰§è¡Œ agent (åº”è¯¥è§¦å‘è‡ªåŠ¨å‹ç¼©)...")
    try:
        # æ‰§è¡Œåˆ° planner èŠ‚ç‚¹å®Œæˆ
        config = {"configurable": {"thread_id": "test_auto_compact"}}
        result = None
        step_count = 0

        async for event in app.astream(state, config, stream_mode="values"):
            result = event
            step_count += 1
            cumul = event.get('cumulative_prompt_tokens', 0)
            print(f"   - Step {step_count}: messages={len(event.get('messages', []))}, "
                  f"auto_compressed={event.get('auto_compressed_this_request', False)}, "
                  f"cumulative_tokens={cumul}")

            # æ‰§è¡Œè‡³å°‘ 4 æ­¥ï¼Œç¡®ä¿ summarization + agent è¿è¡Œ
            if step_count >= 4:
                break

        # 5. éªŒè¯ç»“æœ
        print("[5/5] éªŒè¯ç»“æœ...")
        print(f"\nè‡ªåŠ¨å‹ç¼©ç»“æœ:")
        print(f"   - auto_compressed_this_request: {result.get('auto_compressed_this_request', False)}")
        print(f"   - compact_count: {result.get('compact_count', 0)}")
        print(f"   - å‹ç¼©å‰æ¶ˆæ¯æ•°: {len(state['messages'])}")
        print(f"   - å‹ç¼©åæ¶ˆæ¯æ•°: {len(result.get('messages', []))}")
        print(f"   - cumulative_prompt_tokens: {result.get('cumulative_prompt_tokens', 0)}")

        # æ–­è¨€ï¼šæ£€æŸ¥ compact_count æ˜¯å¦å¢åŠ ï¼ˆè¡¨ç¤ºå‹ç¼©å·²æ‰§è¡Œï¼‰
        initial_compact_count = state.get("compact_count", 0)
        final_compact_count = result.get("compact_count", 0)

        if final_compact_count > initial_compact_count:
            print("\nâœ… è‡ªåŠ¨å‹ç¼©å·²è§¦å‘ï¼")
            print(f"âœ… æ¶ˆæ¯ä» {len(state['messages'])} æ¡å‹ç¼©åˆ° {len(result['messages'])} æ¡")
            print(f"âœ… compact_count å·²æ›´æ–°: {initial_compact_count} â†’ {final_compact_count}")

            # Tokenåº”è¯¥è¢«é‡ç½®æˆ–å¤§å¹…å‡å°‘
            final_tokens = result.get('cumulative_prompt_tokens', 0)
            if final_tokens < state['cumulative_prompt_tokens'] * 0.5:
                print(f"âœ… Token å·²å‡å°‘: {state['cumulative_prompt_tokens']:,} â†’ {final_tokens:,}")
            else:
                print(f"âš ï¸ Token å‡å°‘ä¸æ˜æ˜¾: {state['cumulative_prompt_tokens']:,} â†’ {final_tokens:,}")

            return True
        else:
            print("\nâŒ è‡ªåŠ¨å‹ç¼©æœªè§¦å‘")
            print(f"   å¯èƒ½åŸå› :")
            print(f"   1. Token ä½¿ç”¨ç‡æœªè¾¾åˆ° critical é˜ˆå€¼ (95%)")
            print(f"   2. Context management æœªå¯ç”¨")
            print(f"   3. å‹ç¼©è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯")
            print(f"   compact_count: {initial_compact_count} â†’ {final_compact_count} (æœªå˜åŒ–)")
            return False

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_no_auto_compression_below_threshold():
    """æµ‹è¯•åœ¨é˜ˆå€¼ä»¥ä¸‹ä¸è§¦å‘è‡ªåŠ¨å‹ç¼©"""
    print("\n" + "=" * 80)
    print("æµ‹è¯•ä½äºé˜ˆå€¼æ—¶ä¸è‡ªåŠ¨å‹ç¼©")
    print("=" * 80)

    # æ„å»ºåº”ç”¨
    print("\n[1/4] æ„å»ºåº”ç”¨...")
    app, initial_state_factory, _, _, _ = await build_application()

    # åˆ›å»º state with 80% token usage (below critical)
    print("[2/4] åˆ›å»º state (80% token usage)...")
    state = initial_state_factory()
    messages = [SystemMessage(content="You are a helpful assistant.")]
    for i in range(50):
        messages.append(HumanMessage(content=f"Question {i}"))
        messages.append(AIMessage(content=f"Response {i}"))

    state["messages"] = messages
    state["cumulative_prompt_tokens"] = 102000  # 80% of 128k
    state["compact_count"] = 0
    state["auto_compressed_this_request"] = False

    print(f"   - Token ä½¿ç”¨ç‡: {state['cumulative_prompt_tokens'] / 128000:.1%}")

    # æ·»åŠ æ¶ˆæ¯
    print("[3/4] æ·»åŠ ç”¨æˆ·æ¶ˆæ¯...")
    state["messages"].append(HumanMessage(content="Hello"))

    # æ‰§è¡Œ
    print("[4/4] æ‰§è¡Œ agent (ä¸åº”è§¦å‘è‡ªåŠ¨å‹ç¼©)...")
    try:
        config = {"configurable": {"thread_id": "test_no_auto_compact"}}
        result = None
        step_count = 0

        async for event in app.astream(state, config, stream_mode="values"):
            result = event
            step_count += 1
            # æ‰§è¡Œè‡³å°‘ 2 æ­¥
            if step_count >= 2:
                break

        # éªŒè¯
        if not result.get("auto_compressed_this_request", False):
            print("\nâœ… æ­£ç¡®ï¼šæœªè§¦å‘è‡ªåŠ¨å‹ç¼© (token ä½¿ç”¨ä½äº 95%)")
            return True
        else:
            print("\nâŒ é”™è¯¯ï¼šä¸åº”è¯¥è§¦å‘è‡ªåŠ¨å‹ç¼©")
            return False

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        return False


async def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "=" * 80)
    print("è‡ªåŠ¨å‹ç¼©åŠŸèƒ½æµ‹è¯•å¥—ä»¶")
    print("=" * 80)

    results = []

    # Test 1: è‡ªåŠ¨å‹ç¼©è§¦å‘
    result1 = await test_auto_compression()
    results.append(("è‡ªåŠ¨å‹ç¼©è§¦å‘æµ‹è¯•", result1))

    # Test 2: ä½äºé˜ˆå€¼ä¸è§¦å‘
    result2 = await test_no_auto_compression_below_threshold()
    results.append(("ä½äºé˜ˆå€¼æµ‹è¯•", result2))

    # æ€»ç»“
    print("\n" + "=" * 80)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 80)
    for name, result in results:
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"{status} - {name}")

    all_passed = all(r for _, r in results)
    print("\n" + ("=" * 80))
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
    print("=" * 80)

    return all_passed


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
